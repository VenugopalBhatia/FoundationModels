{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Life is short, eat dessert first\"\n",
    "dc = {w:i for i,w in enumerate(sorted(s.replace(\",\",\"\").split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 5, 2, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([dc[w] for w in s.replace(\",\",\"\").split()])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [-0.4015,  0.9666, -1.1481]]) torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50000\n",
    "torch.manual_seed(123)\n",
    "\n",
    "embed = torch.nn.Embedding(vocab_size,3)\n",
    "embedded_sentence = embed(ts).detach()\n",
    "\n",
    "print(embedded_sentence,embedded_sentence.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self attention mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.7577, 0.4536],\n",
       "        [0.4130, 0.5585],\n",
       "        [0.1170, 0.5578]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Projection matrices\n",
    "d = embedded_sentence.shape[1]\n",
    "dk,dq,dv = 2,2,4\n",
    "\n",
    "Wq = torch.nn.Parameter(torch.rand(d,dq))\n",
    "Wk = torch.nn.Parameter(torch.rand(d,dk))\n",
    "Wv = torch.nn.Parameter(torch.rand(d,dv))\n",
    "Wq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating the Query vector for element 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8175, -0.6962], grad_fn=<SqueezeBackward4>) torch.Size([2])\n",
      "tensor([-1.2935, -1.0338], grad_fn=<SqueezeBackward4>) torch.Size([2])\n",
      "tensor([-1.2396, -0.0786, -0.9770, -0.7058], grad_fn=<SqueezeBackward4>) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "q_2 =  torch.matmul(x_2,Wq)\n",
    "k_2 = torch.matmul(x_2,Wk)\n",
    "v_2 = torch.matmul(x_2,Wv)\n",
    "print(q_2,q_2.shape)\n",
    "print(k_2,k_2.shape)\n",
    "print(v_2,v_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1624, -0.0405],\n",
      "        [-0.8175, -0.6962],\n",
      "        [-2.6408, -2.5129],\n",
      "        [ 0.8645,  0.3767],\n",
      "        [ 1.5005,  2.0251],\n",
      "        [-0.0393, -0.2827]], grad_fn=<MmBackward0>) torch.Size([6, 2])\n",
      "tensor([[-0.0047,  0.1438],\n",
      "        [-1.2935, -1.0338],\n",
      "        [-3.5769, -3.5702],\n",
      "        [ 0.6223,  1.0003],\n",
      "        [ 2.4583,  2.2977],\n",
      "        [-1.0833, -0.0429]], grad_fn=<MmBackward0>) torch.Size([6, 2])\n",
      "tensor([[ 0.1304, -0.0952,  0.1261,  0.0945],\n",
      "        [-1.2396, -0.0786, -0.9770, -0.7058],\n",
      "        [-3.9806, -1.5924, -2.8134, -2.7060],\n",
      "        [ 1.0345,  0.1212,  0.7981,  0.7339],\n",
      "        [ 2.5606,  1.8079,  1.6247,  1.8530],\n",
      "        [-0.3506,  0.6221, -0.4360,  0.1402]], grad_fn=<MmBackward0>) torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "q = embedded_sentence@Wq\n",
    "k = embedded_sentence@Wk\n",
    "v = embedded_sentence@Wv\n",
    "\n",
    "print(q,q.shape)\n",
    "print(k,k.shape)\n",
    "print(v,v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnormalised attention weights, omega for q_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0962, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(q_2.shape)\n",
    "print(k[0].shape)\n",
    "q_2.dot(k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Omega_2 = q_2@k.T\n",
    "Omega_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/vjyjbhhs5h74r8swwy9x49k80000gn/T/ipykernel_70582/488601230.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_weights_2 = F.softmax(Omega_2/(dk**0.5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0177, 0.0667, 0.8698, 0.0081, 0.0015, 0.0363],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "attention_weights_2 = F.softmax(Omega_2/(dk**0.5))\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(v.shape)\n",
    "print(attention_weights_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector_2 = attention_weights_2@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5431, -1.3658, -2.5169, -2.3852], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class: SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,d,dq,dk,dv):\n",
    "        super().__init__()\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.Wq = torch.nn.Parameter(torch.rand(d,dq))\n",
    "        self.Wk = torch.nn.Parameter(torch.rand(d,dk))\n",
    "        self.Wv = torch.nn.Parameter(torch.rand(d,dv))\n",
    "    def forward(self,x):\n",
    "        # x = embedded_sentence\n",
    "        q = x@self.Wq\n",
    "        k = x@self.Wk\n",
    "        v = x@self.Wv\n",
    "\n",
    "        # omega = Unnormalised attention\n",
    "        omega = q@k.T\n",
    "\n",
    "        attention_weights = torch.softmax(\n",
    "            omega/self.dk**0.5\n",
    "            ,dim = -1\n",
    "            )\n",
    "        context_vector =  attention_weights@v\n",
    "        # (n X dv) where n = num_words\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3556, -0.1204, -0.2910, -0.3997],\n",
      "        [-0.8818, -0.9456, -1.0524, -1.5258],\n",
      "        [-1.4612, -1.9542, -2.0118, -2.9217],\n",
      "        [ 0.1046,  0.5374,  0.2862,  0.4735],\n",
      "        [ 1.3173,  2.1931,  1.6684,  2.6063],\n",
      "        [-0.6171, -0.5215, -0.6524, -0.9389]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "d,dk,dq,dv = 3,2,2,4\n",
    "a = SelfAttention(d,dk,dq,dv)\n",
    "context_vectors = a(embedded_sentence)\n",
    "print(context_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FoundationModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
